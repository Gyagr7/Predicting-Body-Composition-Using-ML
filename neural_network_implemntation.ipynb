{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MLP baseline with K-Fold CV over multiple runs and epoch sweep.\n",
    "\n",
    "Install:\n",
    "    pip install numpy pandas scikit-learn torch\n",
    "\n",
    "Optional (if you want GPU):\n",
    "    pip install torch --index-url https://download.pytorch.org/whl/cu121\n",
    "    (choose the CUDA version that matches your system)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, max_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    data_path: str = \"./complete_data.csv\"\n",
    "    excluded_columns: tuple[str, ...] = (\"0\", \"PPT ID\", \"Site\", \"BMD - Total\", \"Race\", \"% fat - Total\", \"Gender\", \"ALM\")\n",
    "    target_columns: tuple[str, ...] = (\"BMD - Total\", \"% fat - Total\", \"ALM\")\n",
    "\n",
    "    batch_size: int = 16\n",
    "    lr: float = 0.01\n",
    "    n_splits: int = 5\n",
    "    n_runs: int = 10\n",
    "\n",
    "    epoch_grid: tuple[int, ...] = tuple(range(50, 450, 50))  # 50,100,...,400\n",
    "    hidden1: int = 10\n",
    "    hidden2: int = 8\n",
    "    num_workers: int = 0  # set >0 if you want multiprocessing dataloading\n",
    "\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibility\n",
    "# ----------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Model\n",
    "# ----------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inputs: int, h1: int = 10, h2: int = 8):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_inputs, h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h1, h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h2, 1),\n",
    "        )\n",
    "        # Xavier init for linear layers\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Data prep (NO leakage)\n",
    "# ----------------------------\n",
    "def get_xy(df: pd.DataFrame, excluded_cols: list[str], target_col: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns raw (unscaled) X, y arrays.\n",
    "    Note: We do NOT scale here to avoid leakage; scaling happens per fold on train only.\n",
    "    \"\"\"\n",
    "    df_use = df.drop(columns=excluded_cols, errors=\"ignore\").copy()\n",
    "\n",
    "    if target_col not in df_use.columns:\n",
    "        raise ValueError(f\"Target column '{target_col}' not found after dropping excluded columns.\")\n",
    "\n",
    "    y = df_use[target_col].to_numpy(dtype=np.float32)\n",
    "    X = df_use.drop(columns=[target_col]).to_numpy(dtype=np.float32)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def make_loaders(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    train_idx: np.ndarray,\n",
    "    test_idx: np.ndarray,\n",
    "    batch_size: int,\n",
    "    num_workers: int = 0,\n",
    ") -> tuple[DataLoader, DataLoader, int, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Fit scaler on train fold ONLY, transform train/test, return DataLoaders and n_inputs.\n",
    "    Also returns y_test (numpy) for normalization.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X[train_idx])\n",
    "    X_test = scaler.transform(X[test_idx])\n",
    "\n",
    "    y_train = y[train_idx].reshape(-1, 1)\n",
    "    y_test = y[test_idx].reshape(-1, 1)\n",
    "\n",
    "    train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "    test_ds = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    n_inputs = X_train.shape[1]\n",
    "    return train_dl, test_dl, n_inputs, y_test.squeeze()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Train / Eval\n",
    "# ----------------------------\n",
    "def train_model(model: nn.Module, train_dl: DataLoader, optimizer: optim.Optimizer, criterion: nn.Module, epochs: int) -> None:\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model: nn.Module, test_dl: DataLoader) -> tuple[float, float, float, np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    for xb, yb in test_dl:\n",
    "        out = model(xb).view(-1).cpu().numpy()\n",
    "        yt = yb.view(-1).cpu().numpy()\n",
    "        preds.append(out)\n",
    "        trues.append(yt)\n",
    "\n",
    "    y_pred = np.concatenate(preds)\n",
    "    y_true = np.concatenate(trues)\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mx = max_error(y_true, y_pred)\n",
    "    return mse, mae, mx, y_pred, y_true\n",
    "\n",
    "\n",
    "def percent_rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    denom = np.sqrt(np.mean(y_true**2)) + 1e-12\n",
    "    return 100.0 * rmse / denom\n",
    "\n",
    "\n",
    "def percent_mae(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    denom = np.mean(np.abs(y_true)) + 1e-12\n",
    "    return 100.0 * mae / denom\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Experiment per target\n",
    "# ----------------------------\n",
    "def run_experiment(df: pd.DataFrame, target_col: str, cfg: Config)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
